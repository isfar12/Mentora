{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57f86ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f31099b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history=[]\n",
    "# chat_history.extend([\n",
    "#     HumanMessage(\"Who was the first president of the United States?\"),\n",
    "#     AIMessage(\"The first president of the United States was George Washington.\"),\n",
    "#     HumanMessage(\"What year was he inaugurated?\"),\n",
    "#     AIMessage(\"George Washington was inaugurated as president in 1789.\")\n",
    "# ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "820647bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d0f4b2",
   "metadata": {},
   "source": [
    "# Contextualizing the chained question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7003b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_system_prompt = (\n",
    "    \"You must rewrite the user question to be standalone using chat history context. \"\n",
    "    \"Return ONLY the rewritten question - nothing else. No explanations, no answers. \"\n",
    "    \"Example: If user asks 'Was he the first president?' and history mentions George Washington, \"\n",
    "    \"return: 'Was George Washington the first president?'\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ba36d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_full_prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",contextualize_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be9321b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "llm=ChatOllama(model=\"gemma3:1b\", temperature=0.5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "069d870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualize_chain=contextualize_full_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4aaec9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Of which country was he president?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contextualize_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Of which country he was president?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50700449",
   "metadata": {},
   "source": [
    "# Using LLM to answer relevant question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67ed3c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "huggingface_embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"intfloat/e5-base-v2\"\n",
    ")\n",
    "\n",
    "persist_directory = \"vector_store/chroma_vector_store\" \n",
    "# Load the Chroma vector store from the local directory\n",
    "vector_store = Chroma(\n",
    "    persist_directory=persist_directory,\n",
    "    embedding_function=huggingface_embeddings,\n",
    "    collection_name=\"all_documents\"\n",
    ")\n",
    "retriever=vector_store.as_retriever(search_kwargs={\"k\":3},search_type=\"similarity\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "636c67f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "\n",
    "history_aware_retriever=create_history_aware_retriever(llm,retriever,contextualize_full_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f15ee3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "qa_prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant. Use the following context to answer\"),\n",
    "        (\"system\",\"{context}\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain=create_stuff_documents_chain(llm,qa_prompt)\n",
    "rag_chain=create_retrieval_chain(history_aware_retriever,question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07b29d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "\n",
    "DB_NAME = \"rag_app.db\"\n",
    "\n",
    "def get_db_connection():\n",
    "    conn = sqlite3.connect(DB_NAME)\n",
    "    conn.row_factory = sqlite3.Row\n",
    "    return conn\n",
    "\n",
    "def create_application_logs():\n",
    "    conn = get_db_connection()\n",
    "    conn.execute('''CREATE TABLE IF NOT EXISTS application_logs\n",
    "    (id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    session_id TEXT,\n",
    "    user_query TEXT,\n",
    "    gpt_response TEXT,\n",
    "    model TEXT,\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP)''')\n",
    "    conn.close()\n",
    "\n",
    "def insert_application_logs(session_id, user_query, gpt_response, model):\n",
    "    conn = get_db_connection()\n",
    "    conn.execute('INSERT INTO application_logs (session_id, user_query, gpt_response, model) VALUES (?, ?, ?, ?)',\n",
    "                 (session_id, user_query, gpt_response, model))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def get_chat_history(session_id):\n",
    "    conn = get_db_connection()\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('SELECT user_query, gpt_response FROM application_logs WHERE session_id = ? ORDER BY created_at', (session_id,))\n",
    "    messages = []\n",
    "    for row in cursor.fetchall():\n",
    "        messages.extend([\n",
    "            {\"role\": \"human\", \"content\": row['user_query']},\n",
    "            {\"role\": \"ai\", \"content\": row['gpt_response']}\n",
    "        ])\n",
    "    conn.close()\n",
    "    return messages\n",
    "\n",
    "# Initialize the database\n",
    "create_application_logs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b1050d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: What is GreenGrow Innovations?\n",
      "AI: Okay, let’s dive into GreenGrow Innovations. Here’s what I’ve gathered based on the context you provided:\n",
      "\n",
      "GreenGrow Innovations is a company focused on **developing and deploying advanced, sustainable, and intelligent solutions for the smart grid and energy sector.**\n",
      "\n",
      "Here’s a breakdown of what they generally do and their focus:\n",
      "\n",
      "*   **Smart Grid Technology:** They specialize in creating technologies to improve the efficiency and reliability of the electrical grid.\n",
      "*   **Energy Efficiency:** A key part of their work is optimizing energy distribution and reducing waste.\n",
      "*   **Data Analytics & IoT:** They utilize data from sensors and other devices to create insights and automate processes within the grid.\n",
      "*   **Innovation:** They are known for their cutting-edge research and development in areas like smart metering, grid monitoring, and predictive maintenance.\n",
      "\n",
      "**In short, GreenGrow Innovations is a company working to make the electricity grid more efficient, reliable, and sustainable.**\n",
      "\n",
      "**Resources for More Information:**\n",
      "\n",
      "*   **Their Website:** [https://www.greengrowinnovations.com/](https://www.greengrowinnovations.com/) - This is the best place for the most up-to-date information.\n",
      "\n",
      "Do you have any specific questions about GreenGrow Innovations that you’d like me to answer? For example, are you interested in:\n",
      "\n",
      "*   Their specific technologies?\n",
      "*   Their current projects?\n",
      "\n",
      "Human: What was their first product?\n",
      "AI: According to GreenGrow Innovations’ website, their first product was the **“Smart Meter”**.\n",
      "\n",
      "They launched this in 2016 as a pilot project to demonstrate the potential of smart metering technology for grid management. It was a foundational step in their broader focus on the smart grid.\n"
     ]
    }
   ],
   "source": [
    "# Example usage for a new user\n",
    "session_id = str(uuid.uuid4())\n",
    "question = \"What is GreenGrow Innovations?\"\n",
    "chat_history = get_chat_history(session_id)\n",
    "answer = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})['answer']\n",
    "insert_application_logs(session_id, question, answer, \"gemma3:1b\")\n",
    "print(f\"Human: {question}\")\n",
    "print(f\"AI: {answer}\\n\")\n",
    "\n",
    "# Example of a follow-up question\n",
    "question2 = \"What was their first product?\"\n",
    "chat_history = get_chat_history(session_id)\n",
    "answer2 = rag_chain.invoke({\"input\": question2, \"chat_history\": chat_history})['answer']\n",
    "insert_application_logs(session_id, question2, answer2, \"gemma3:1b\")\n",
    "print(f\"Human: {question2}\")\n",
    "print(f\"AI: {answer2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa2e1cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'human', 'content': 'What is GreenGrow Innovations?'},\n",
       " {'role': 'ai',\n",
       "  'content': 'Okay, let’s dive into GreenGrow Innovations. Here’s what I’ve gathered based on the context you provided:\\n\\nGreenGrow Innovations is a company focused on **developing and deploying advanced, sustainable, and intelligent solutions for the smart grid and energy sector.**\\n\\nHere’s a breakdown of what they generally do and their focus:\\n\\n*   **Smart Grid Technology:** They specialize in creating technologies to improve the efficiency and reliability of the electrical grid.\\n*   **Energy Efficiency:** A key part of their work is optimizing energy distribution and reducing waste.\\n*   **Data Analytics & IoT:** They utilize data from sensors and other devices to create insights and automate processes within the grid.\\n*   **Innovation:** They are known for their cutting-edge research and development in areas like smart metering, grid monitoring, and predictive maintenance.\\n\\n**In short, GreenGrow Innovations is a company working to make the electricity grid more efficient, reliable, and sustainable.**\\n\\n**Resources for More Information:**\\n\\n*   **Their Website:** [https://www.greengrowinnovations.com/](https://www.greengrowinnovations.com/) - This is the best place for the most up-to-date information.\\n\\nDo you have any specific questions about GreenGrow Innovations that you’d like me to answer? For example, are you interested in:\\n\\n*   Their specific technologies?\\n*   Their current projects?'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511cd4a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
